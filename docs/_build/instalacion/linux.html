---
interact_link: content/instalacion/linux.ipynb
kernel_name: python3
has_widgets: false
title: |-
  LINUX
prev_page:
  url: /intro.html
  title: |-
    INICIO
next_page:
  url: 
  title: |-
    
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---
<main class="jupyter-page">
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="INSTALACI&#211;N">INSTALACI&#211;N<a class="anchor-link" href="#INSTALACI&#211;N"> </a></h1><p style="text-align: justify;">Polynote actualmente solo se prueba en Linux y MacOS, utilizando el navegador Chrome como cliente</p><h3 id="MAC:">MAC:<a class="anchor-link" href="#MAC:"> </a></h3><ul>
<li>Se necesita el manejador de paquetes <a href="https://brew.sh">Homebrew</a>.</li>
<li>Puede instalar Spark localmente con <code>brew install apache-spark</code></li>
</ul>
<h3 id="LINUX:">LINUX:<a class="anchor-link" href="#LINUX:"> </a></h3><ul>
<li><p>Desactive Spark donde quiera y configure su entorno para que <strong>SPARK_HOME</strong> apunte a la ubicación de Spark.</p>
</li>
<li><p>Luego agregue <code>SPARK_HOME/bin/</code> a su PATH.</p>
</li>
<li><p>También necesitara un <strong>JDK instalado</strong> y <strong>JAVA_HOME</strong> configurado correctamente.</p>
</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;✨ Comience por un <code>sudo apt-get update</code> para actualizar todos los repositorios.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;✨ Instale Java (Esto instala Java11 por defecto) <code>sudo apt-get install default-jdk</code>.</p>
<ul>
<li><p><a href="https://github.com/polynote/polynote/releases/download/0.2.13/polynote-dist-2.12.tar.gz">Descargue polynote</a> y luego <code>tar -zxvpf polynote-dist.tar.gz</code>.</p>
</li>
<li><p><a href="https://www-eu.apache.org/dist/spark/spark-3.0.0-preview/spark-3.0.0-preview-bin-hadoop2.7.tgz">Descargue spark</a>, y a continuación <code>tar -zxvf spark-2.4.4-bin-hadoop2.7.tgz</code>.</p>
</li>
<li><p>Establezca <code>JAVA_HOME: export JAVA_HOME=/usr/lib/jvm/default-java/</code></p>
</li>
<li><p>Establezca <code>SPARK_HOME: export SPARK_HOME=</code>pwd<code>/spark-2.4.4-bin-hadoop2.7/</code></p>
</li>
<li><p>Establezca PATH: <code>export PATH="PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin"</code></p>
</li>
<li><p>Compruebe si spark está configurado correctamente, al ejecutar <code>spark-submit</code>, debería ver información de uso.</p>
</li>
</ul>
<h3 id="Configuraci&#243;n">Configuraci&#243;n<a class="anchor-link" href="#Configuraci&#243;n"> </a></h3><ul>
<li><p style="text-align: justify;">Compatibilidad con Python: para ejecutar el código de Python, necesitará tener instalado una versión de <strong>Python 3</strong> y <strong>pip</strong> o <strong>pip3</strong>.</p></li>
</ul>

<pre><code>sudo apt-get install python3.6</code></pre>

<pre><code>sudo apt install python-pip</code></pre>
<ul>
<li><p style="text-align: justify;">También tendrá que instalar algunas dependencias de Python como <strong>jep,jedi y virtualenv</strong></p></li>
</ul>

<pre><code>pip install jep jedi pyspark virtualenv</code></pre>
<ul>
<li><p style="text-align: justify;">Además, es probable que necesite instalar <strong>pandas y numpy</strong></p></li>
</ul>

<pre><code>pip install pandas</code></pre>

<pre><code>pip install numpy</code></pre>
<h3 id="Ejecutar:">Ejecutar:<a class="anchor-link" href="#Ejecutar:"> </a></h3><ul>
<li><code>./polynote</code></li>
</ul>

</div>
</div>
</div>
</div>

 


</main>
